---
title: "Activity 4: Bayesian hierarchical modeling"
author: "Kevin Ross (Cal Poly) and Jingchen (Monika) Hu (Vassar), eCOTS 2022"
output:
  html_document: 
    number_sections: true
  pdf_document: default
---

```{r, warning = FALSE}

library(knitr)

knitr::opts_chunk$set(warning = FALSE, message = FALSE, echo = TRUE)

```

```{r}

library(tidyverse)
library(bayesplot)

```

# Introduction

In many applications, observations are nested in groups, such as students' test scores from different schools and movie ratings from different genres. 

For such applications, on the one hand, following the commonly used independent assumption of observations is not very appropriate. In terms of (Bayesian) modeling, this means treating observations as $i.i.d.$ from the same distribution with the same parameter(s) is not sensible. On the other hand, using either separate estimates (i.e., treating each group as separate from each other and build a model for each group) or combined estimates (i.e., treating all observations as one and build one model for all observations) seems not ideal. 

In Bayesian modeling, the hierarchical model approach can effectively take into account of the fact that observations belong to different groups, while simultaneously borrowing information across groups so that groups with few observations can have improved inference. As usual, model parameters are considered as random and therefore one can use **prior** distributions to quantify the degree of uncertainty in these parameters. With appropriate **Markov chain Monte Carlo (MCMC)** estimation tools, one could arrive at the **posterior** distributions of these parameters, based on which one can answer relevant research questions.

In this Activity, we will introduce a sample of animation movie ratings from 2010 and illustrate the usefulness of Bayesian hierarchical models in such settings. We will walk through the details of a hierarchical model that can be built for the movie ratings sample, how to perform MCMC estimation using the ```brms``` R package and how to perform MCMC diagnostics with 2 MCMC chains, and several posterior inference techniques to answer relevant questions about the data.

<span style="color:red">Discussion questions are in red throughout this Activity. </span>

# A sample of animation movie ratings from 2010

The sample comes from MovieLens, which includes 8 animation movies with 55 ratings. Each rating is for a movie completed by a user. Some movies have many ratings while others have few (fewest: only 1 rating).

Variable \& Description:

- **Title**: movie title

- **Rating**: movie rating by a user


```{r fig.height = 3, fig.width = 6, fig.align = "center", size = "footnotesize", echo = FALSE}
MovieRatings = read.csv("2010_animation_ratings.csv", header = TRUE, sep = ",")

MovieRatings %>%
  mutate(Title = as.character(title),
         Title = recode(Title,
                  "Shrek Forever After (a.k.a. Shrek: The Final Chapter) (2010)" = "Shrek Forever",
                  "How to Train Your Dragon (2010)" = "Dragon",
                  "Toy Story 3 (2010)" = "Toy Story 3",
                  "Tangled (2010)" = "Tangled",
                  "Despicable Me (2010)" = "Despicable Me",
                  "Legend of the Guardians: The Owls of Ga'Hoole (2010)" = "Guardians",
                  "Megamind (2010)" = "Megamind",
                  "Batman: Under the Red Hood (2010)" = "Batman")) ->
           MovieRatings

ggplot(MovieRatings, aes(Title, rating)) +
  geom_jitter(width = 0.2,
              size = 1) +
  coord_flip() +
  ylab("Rating") + 
  theme_bw(base_size = 10, base_family = "")
```

# Highlights in teaching

- Bayesian approaches are natural for observations nested in groups

- Using 2 or more MCMC chains
    - Diagnostics
    - Inference
    
- Inference
    - Credible intervals
    - Prediction
    - Model checking
    
- Additional inference topics for hierarchical modeling
    - Shrinkage / pooling effects
    - Sources of variability


# A hierarchical / multi-level model 

## The sampling model

- Without loss of generality, assume a group-specific normal model for movie $j$:
\begin{eqnarray}
Y_{ij} \overset{i.i.d.}{\sim} \textrm{Normal}(\mu_j, \sigma),
\end{eqnarray}
where $i = 1, \cdots, n_j$ and $n_j$ is the number of observations in group $j$. 

- Is a commonly shared $\sigma$ reasonable? If not, $\sigma$ can be group-specific.

- Model parameters: $\{\mu_1, \cdots, \mu_J, \sigma\}$.

<span style="color:red">Discussion question: How many parameters and what are they in this hierarchical model? What types of prior distributions you would like to give to them and why?</span>

<span style="color:red">Discussion question: Do you think a commonly shared $\sigma$ is reasonable? Why or why not?</span>


## A two-stage prior for $\{\mu_1, \cdots, \mu_J\}$

**Stage 1**

- All movies are animation movies, we could assume that the mean ratings are similar across movies

- First stage: the same normal prior distribution for each mean $\mu_j$
\begin{equation}
\mu_j \mid \mu, \tau \sim \textrm{Normal}(\mu, \tau).
\end{equation}

- This prior allows information pooled across movies (groups).
    - If $\tau$ is large, the $\mu_j$'s are very different a priori $\rightarrow$ modest pooling in parameter estimation.
    - If $\tau$ is small, the $\mu_j$'s are very similar a priori $\rightarrow$ large pooling in parameter estimation.

- $\mu$ and $\tau$: hyperparameters, and treated random.

**Stage 2**

- Second stage: weakly informative hyperpriors for hyperparameters
\begin{eqnarray}
\mu &\sim& \textrm{Normal}(3, 1), \\
\tau &\sim& \textrm{Cauchy}^+(0, 1).
\end{eqnarray}

- After posterior inference:
    - The posterior of $\mu$ is informative about an average mean rating.
    - The posterior of $\tau$ is informative about the variation among the $\mu_j$'s.

**Others**

- Weakly informative prior for $\sigma$:
\begin{eqnarray}
\sigma &\sim& \textrm{Cauchy}^+(0, 1).
\end{eqnarray}

```{r  echo = FALSE, fig.height = 3, fig.width = 6, fig.align = "center"}
knitr::include_graphics("treediagram.png")
```

# Bayesian inference with the brms package

## MCMC estimation

Use chosen priors; one can also use default priors.

```{r, results = 'hide'}
library(brms)
hm_fit <- brms::brm(data = MovieRatings,
                    family = gaussian,
                    formula = rating ~ 1 + (1 | Title),
                    prior = c(prior(normal(3, 1), class = Intercept),
                              prior(cauchy(0, 1), class = sd),
                              prior(cauchy(0, 1), class = sigma)),
                    iter = 20000, 
                    warmup = 10000, 
                    thin = 10, 
                    chains = 2, 
                    seed = 852)
```

**Important concepts**

- **iter**: the number of MCMC iterations
- **warmup**: the number of burn-in iterations
- **thin**: thinning rate
- **chains**: the number of MCMC chains
- **seed**: the seed

## MCMC diagnostics

**Traceplots**

- Look for "stickiness" which indicates convergence issues

**Autocorrelation plots (acf)**

- Look for slow decrease of the autocorrelation which indicates convergence issues

```{r fig.height = 3, fig.width = 6, fig.align = "center"}
library(bayesplot)
bayesplot::mcmc_trace(x = hm_fit,
                      pars = c("sd_Title__Intercept"))
bayesplot::mcmc_acf_bar(x = hm_fit,
                        pars = c("sd_Title__Intercept"))
```

<span style="color:red">Discussion question: How do the traceplots and ACF plots suggest about the convergence of MCMC? </span>

## Posterior inference

```{r fig.height = 3, fig.width = 6, fig.align = "center"}
post_hm <- posterior_samples(hm_fit)
bayesplot::mcmc_areas(x = post_hm, 
                      pars = c("b_Intercept", "r_Title[Batman,Intercept]"),
                      prob = 0.95)
```

```{r fig.height = 3, fig.width = 6, fig.align = "center"}
bayesplot::mcmc_areas(x = post_hm, 
                      pars = c("b_Intercept", 
                               "r_Title[Batman,Intercept]", 
                               "r_Title[Despicable.Me,Intercept]", 
                               "r_Title[Dragon,Intercept]",
                               "r_Title[Guardians,Intercept]",
                               "r_Title[Megamind,Intercept]",
                               "r_Title[Shrek.Forever,Intercept]",
                               "r_Title[Tangled,Intercept]",
                               "r_Title[Toy.Story.3,Intercept]"), 
                      prob = 0.95)
```

<span style="color:red">Discussion question: What does the posterior summary plot suggest about the average movie ratings? Which one(s) have the highest average ratings and which one(s) have the lowest average ratings in the posterior?</span>

Additional inference:

- **Prediction**: ```predict(fit)```

- **Model checking (posterior predictive check)**: ```pp_check(fit)```

- **Shrinkage / pooling effects**:

```{r fig.height = 3, fig.width = 6, fig.align = "center", echo = FALSE}
J <- 8
Post_Mus <- post_hm[, 1] + post_hm[, 4:11]
Post_Means <- colMeans(Post_Mus)

MovieRatings %>% group_by(Group_Number) %>%
  summarize(Title = first(title),
            N = n(), M = mean(rating),
            SE = sd(rating) / sqrt(N)) -> Ind_Stats

Means1 <- data.frame(Type = "Sample", Mean = Ind_Stats$M)
Means2 <- data.frame(Type = "Posterior", Mean = Post_Means)
Means1$Title <- c("Dragon", "Toy Story 3", "Shrek Forever",
                  "Despicable Me", "Batman", "Guardians",
                  "Megamind", "Tangled")
Means2$Title <- c("Batman", "Despicable Me", "Dragon", "Guardians",
                  "Megamind", "Shrek Forever",
                   "Tangled", "Toy Story 3")
df <- rbind(Means1, Means2)
df$Type <- factor(df$Type, levels = c("Sample", "Posterior"))
ggplot(df,
       aes(Type, Mean, group=Title)) +
  geom_line() + geom_point() +
  annotate(geom = "text",
           x = 0.75,
           y = Means1$Mean + c(0.05, 0, 0.05, 0,
                               0, -0.05, 0, 0),
           size = 2,
           label = Means1$Title) +
  theme_bw(base_size = 15, base_family = "")
```

<span style="color:red">Discussion question: What does this shrinkage / pooling effects plot suggest? Recall that the movie Batman has only one rating of 5 in the sample. Compare the sample mean to the posterior mean for Batman rating. What does the hierarchical model do for movies with only one rating, such as Batman?</span>

- **Sources of variability**:

- Two sources of variability in $Y_{ij}$:
\begin{eqnarray*}
Y_{ij} &\overset{i.i.d.}{\sim}& \textrm{Normal}(\mu, \sigma) \,\,\, \text{[within-group variability]} \\
\mu_j &\sim& \textrm{Normal}(\mu, \tau) \,\,\, \text{[between-group variability]}
\end{eqnarray*}

- To compare these two sources of variability, one can compute the fraction
\begin{equation*}
R = \frac{\tau^2}{\tau^2 + \sigma^2}
\end{equation*}
from the posterior draws of $\tau$ and $\sigma$.

- If $R \rightarrow 1$, the higher the between-group variability.

```{r fig.height = 2, fig.width = 6, fig.align = "center"}
tau_draws <- post_hm[,"sd_Title__Intercept"]
sigma_draws <- post_hm[,"sigma"]
R <- tau_draws^2/(tau_draws^2 + sigma_draws^2)
quantile(R, c(0.025, 0.975))
```


```{r fig.height = 2, fig.width = 6, fig.align = "center", echo = FALSE}
df <- as.data.frame(R)
ggplot(df, aes(x=R)) + 
  geom_density() + 
  labs(title="Density of R") + 
  theme_bw(base_size = 15, base_family = "")
```



```{r fig.height = 3, fig.width = 6, fig.align = "center"}
bayesplot::mcmc_areas(x = post_hm, 
                      pars = c("sd_Title__Intercept", "sigma"),
                      prob = 0.95)
```

<span style="color:red">Discussion question: Given these results, which source of variability do you think is dominating for the outcome variable? Why?</span>

# Additional resources

- [Fully expanded analysis of the movie ratings example with JAGS](https://bayesball.github.io/BOOK/bayesian-hierarchical-modeling.html#hierarchical-normal-modeling)

- [Hierarchical modeling for binomial outcome data with JAGS](https://bayesball.github.io/BOOK/bayesian-hierarchical-modeling.html#hierarchical-beta-binomial-modeling)

- [Hierarchical modeling of proportions with brms](https://bayesball.github.io/BRMS/multilevel-modeling-of-proportions.html)

- [Hierarchical regression with brms](https://bayesball.github.io/BRMS/multilevel-regression.html)